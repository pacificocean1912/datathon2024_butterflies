{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf7cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jonat\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonat\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install requests\n",
    "!python -m pip install beautifulsoup4\n",
    "!python -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aae1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1749e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url_for_filename(url):\n",
    "    # Extract year and season from URL\n",
    "    year_match = re.search(r'year=(\\d{4})', url)\n",
    "    season_match = re.search(r'season=([^&]*)', url)\n",
    "\n",
    "    year = year_match.group(1) if year_match else 'unknown_year'\n",
    "    season = season_match.group(1) if season_match and season_match.group(1) else 'all_seasons'\n",
    "\n",
    "    return f\"monarch_data_{year}_{season}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5127993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_table_data(url):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        print(f\"Fetching data from {url}\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the table\n",
    "        table = soup.find('table')\n",
    "        if not table:\n",
    "            print(f\"No table found at {url}\")\n",
    "            return None\n",
    "\n",
    "        # Find all table rows\n",
    "        rows = table.find_all('tr')\n",
    "        if not rows:\n",
    "            print(f\"No rows found in table at {url}\")\n",
    "            return None\n",
    "\n",
    "        # Lists to store the data\n",
    "        data = {\n",
    "            'Date': [],\n",
    "            'Town': [],\n",
    "            'State/Province': [],\n",
    "            'Latitude': [],\n",
    "            'Longitude': [],\n",
    "            'Number': [],\n",
    "        }\n",
    "\n",
    "        # Iterate through rows and extract data\n",
    "        for row in rows:\n",
    "            cols = row.find_all(['th', 'td'])\n",
    "            if len(cols) >= 7:  # Ensure row has enough columns\n",
    "                data['Date'].append(cols[1].get_text(strip=True))\n",
    "                data['Town'].append(cols[2].get_text(strip=True))\n",
    "                data['State/Province'].append(cols[3].get_text(strip=True))\n",
    "                data['Latitude'].append(cols[4].get_text(strip=True))\n",
    "                data['Longitude'].append(cols[5].get_text(strip=True))\n",
    "                data['Number'].append(cols[6].get_text(strip=True))\n",
    "\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch data from {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c54d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "       \n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2017&season=fall\", # 2017 Fall\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2018&season=fall\", # 2018 Fall\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2019&season=fall\", # 2019 Fall\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2020&season=fall\", # 2020 Fall\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2021&season=fall\", # 2021 Fall\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2022&season=fall\", # 2022 Fall\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2023&season=fall\", # 2023 Fall\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2024&season=fall\", # 2024 Fall\n",
    "\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2017&season=spring\", # 2017 Spring\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2018&season=spring\", # 2018 Spring\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2019&season=spring\", # 2019 Spring\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2020&season=spring\", # 2020 Spring\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2021&season=spring\", # 2021 Spring\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2022&season=spring\", # 2022 Spring\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2023&season=spring\", # 2023 Spring\n",
    "        # \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2024&season=spring\", # 2024 Spring        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2012&season=spring\", # 2012 spring\n",
    "        \"https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2012&season=fall\", # 2012 spring\n",
    "]\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if 'saved_data/' is a valid path\n",
    "if not os.path.exists('saved_data/'):\n",
    "    os.makedirs('saved_data/')\n",
    "    print(\"'saved_data/' directory created.\")\n",
    "else:\n",
    "    print(\"'saved_data/' directory already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eabffa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2012&season=spring\n",
      "Data from https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2012&season=spring saved to saved_data/monarch_data_2012_spring_20241006_072643.csv\n",
      "Records in this file: 183\n",
      "\n",
      "First few rows of data from saved_data/monarch_data_2012_spring_20241006_072643.csv:\n",
      "       Date           Town  State/Province  Latitude  Longitude  Number\n",
      "0      Date           Town  State/Province  Latitude  Longitude  Number\n",
      "1  07/28/12  Springerville              AZ      34.2     -109.4       1\n",
      "2  07/26/12       Chandler              AZ      33.3     -111.9       1\n",
      "3  07/26/12   Newport News              VA      37.1      -76.5       1\n",
      "4  07/25/12      Lakeville              NY      42.8      -77.7       2\n",
      "\n",
      "==================================================\n",
      "\n",
      "Fetching data from https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2012&season=fall\n",
      "Data from https://journeynorth.org/sightings/querylist.html?map=monarch-adult-fall&year=2012&season=fall saved to saved_data/monarch_data_2012_fall_20241006_072643.csv\n",
      "Records in this file: 3335\n",
      "\n",
      "First few rows of data from saved_data/monarch_data_2012_fall_20241006_072643.csv:\n",
      "       Date        Town  State/Province  Latitude  Longitude  Number\n",
      "0      Date        Town  State/Province  Latitude  Longitude  Number\n",
      "1  12/27/12  Santa Cruz              CA      37.1     -122.2    4000\n",
      "2  12/27/12  Santa Cruz              CA      37.1     -122.2    3500\n",
      "3  12/26/12   Angangueo             MIC      19.6     -100.3       1\n",
      "4  12/26/12      Goleta              CA      34.4     -119.9       1\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "        df = scrape_table_data(url)\n",
    "        if df is not None and not df.empty:\n",
    "            base_filename = clean_url_for_filename(url)\n",
    "            filename = f'saved_data/{base_filename}_{timestamp}.csv'\n",
    "\n",
    "            # Save to CSV\n",
    "            df.to_csv(filename, index=False)    \n",
    "            print(f\"Data from {url} saved to {filename}\")\n",
    "            print(f\"Records in this file: {len(df)}\")\n",
    "\n",
    "\n",
    "            # Display first few rows\n",
    "            print(f\"\\nFirst few rows of data from {filename}:\")\n",
    "            print(df.head())\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        else:\n",
    "            print(f\"No data was successfully scraped from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "696d8536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cleaned_merged.csv', 'combined_fall_data.csv', 'coordinates.csv', 'filtered_data.csv', 'filtered_data_2.csv', 'monarch_data_2012_fall_20241006_072643.csv', 'monarch_data_2012_spring_20241006_072643.csv', 'monarch_data_2017_fall_20241005_164848.csv', 'monarch_data_2017_spring_20241005_164848.csv', 'monarch_data_2018_fall_20241005_164848.csv', 'monarch_data_2018_spring_20241005_164848.csv', 'monarch_data_2019_fall_20241005_164848.csv', 'monarch_data_2019_spring_20241005_164848.csv', 'monarch_data_2020_fall_20241005_164848.csv', 'monarch_data_2020_spring_20241005_164848.csv', 'monarch_data_2021_fall_20241005_164848.csv', 'monarch_data_2021_spring_20241005_164848.csv', 'monarch_data_2022_fall_20241005_164848.csv', 'monarch_data_2022_spring_20241005_164848.csv', 'monarch_data_2023_fall_20241005_164848.csv', 'monarch_data_2023_spring_20241005_164848.csv', 'monarch_data_2024_fall_20241005_164848.csv', 'monarch_data_2024_spring_20241005_164848.csv', 'updated_dataset.csv']\n",
      "Error processing cleaned_merged.csv: 'NoneType' object has no attribute 'to_csv'\n",
      "Error processing combined_fall_data.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing coordinates.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing filtered_data.csv: 'NoneType' object has no attribute 'to_csv'\n",
      "Error processing filtered_data_2.csv: 'NoneType' object has no attribute 'to_csv'\n",
      "Error processing monarch_data_2012_fall_20241006_072643.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2012_spring_20241006_072643.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2017_fall_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2017_spring_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2018_fall_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2018_spring_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2019_fall_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2019_spring_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2020_fall_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2020_spring_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2021_fall_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2021_spring_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2022_fall_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2022_spring_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2023_fall_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2023_spring_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2024_fall_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing monarch_data_2024_spring_20241005_164848.csv: \"['Unnamed: 0'] not found in axis\"\n",
      "Error processing updated_dataset.csv: 'NoneType' object has no attribute 'to_csv'\n"
     ]
    }
   ],
   "source": [
    "# read all the csv files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "directory = 'saved_data/'\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "print(csv_files)\n",
    "# Check if there are any CSV files in the directory\n",
    "if not csv_files:\n",
    "    print(f\"No CSV files found in {directory}\")\n",
    "\n",
    "for file in csv_files:\n",
    "    input_path = os.path.join(directory, file)\n",
    "        \n",
    "    try:\n",
    "        # Read the CSV file, skipping the first two rows\n",
    "        df = pd.read_csv(input_path)\n",
    "        df=df.iloc[1:,:]\n",
    "        # Create output filename\n",
    "        file_name, file_extension = os.path.splitext(file)\n",
    "        output_file = f\"{file_name}{file_extension}\"\n",
    "        output_path = os.path.join(directory, output_file)\n",
    "\n",
    "        # Drop the \tUnnamed: 0 column\n",
    "        df=df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        \n",
    "\n",
    "        # Save the modified DataFrame to a new CSV file\n",
    "        df.to_csv(output_path)\n",
    "        print(f\"Successfully processed: {file} -> {output_file}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b824836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26408b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
